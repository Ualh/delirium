{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import interp\n",
    "import scipy\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "from itertools import cycle\n",
    "from inspect import signature\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    recall_score, classification_report, confusion_matrix, f1_score, auc, roc_curve,\n",
    "    precision_recall_curve, average_precision_score, matthews_corrcoef,\n",
    "    mean_squared_error, r2_score, mean_absolute_error\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import (\n",
    "    Bidirectional, LSTM, Lambda, Dropout, Dense, TimeDistributed, Masking,\n",
    "    Activation, Input, Reshape, Embedding, GaussianNoise\n",
    ")\n",
    "from keras import initializers, optimizers, regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eicu_result(min_time,skip_time):\n",
    "\n",
    "    SEED_VALUE = 36\n",
    "    seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    random.seed(SEED_VALUE)\n",
    "    os.environ['PYTHONHASHSEED']=str(SEED_VALUE)\n",
    "    tf.set_random_seed(SEED_VALUE)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "    \n",
    "    CV = True\n",
    "    BATCH_SIZE = 128\n",
    "    TASK = '%d_%d'%(min_time,skip_time)\n",
    "    params = {'lr':0.000075,'hidden_units':128,'dropout':0.2,'epochs':50}\n",
    "    #pos\n",
    "    def pos_selection(df_pos,skip_time,min_time):\n",
    "        posl = []\n",
    "        posdf = pd.DataFrame(columns=df_pos.columns)\n",
    "        all_matches = df_pos[df_pos['labelpt'] == df_pos['labelrec']]\n",
    "\n",
    "        for i, p_id in enumerate(all_matches['patientunitstayid'].unique()):\n",
    "            df_p_id = df_pos[df_pos['patientunitstayid'] == p_id]\n",
    "            idx = all_matches[all_matches['patientunitstayid'] == p_id].index[0]\n",
    "            t = df_pos.iloc[idx].itemoffset\n",
    "            if t > (min_time + skip_time):\n",
    "                posl.append(df_p_id[(df_p_id['itemoffset'] < (t-skip_time)) & (df_p_id['itemoffset'] > (t-(skip_time+min_time)))])\n",
    "\n",
    "        posdf = pd.concat(posl,axis=0)\n",
    "        return posdf\n",
    "\n",
    "    #neg\n",
    "    def neg_selection(df_neg,skip_time,min_time):\n",
    "        negl = []\n",
    "        negdf = pd.DataFrame(columns=df_neg.columns)\n",
    "\n",
    "        for i, p_id in enumerate(df_neg['patientunitstayid'].unique()):\n",
    "            df_p_id = df_neg[df_neg['patientunitstayid'] == p_id]\n",
    "            t = df_p_id.iloc[-1].itemoffset\n",
    "            if t > (min_time + skip_time):\n",
    "                negl.append(df_p_id[(df_p_id['itemoffset'] < (t-skip_time)) &(df_p_id['itemoffset'] > (t-(min_time+skip_time)))])\n",
    "        negdf = pd.concat(negl,axis=0)\n",
    "        return negdf\n",
    "    eicu_df  = pd.read_csv(\"eicu_df_all_24los_normed.csv\")\n",
    "    # ADD VASO\n",
    "    eicu_df['vaso_dose'] = np.nan\n",
    "    eicu_df['vaso_dose'] = eicu_df['rate_epinephrine']+eicu_df['rate_norepinephrine'] + eicu_df['rate_phenylephrine']/10 + eicu_df['rate_dopamine']/2\n",
    "    eicu_df.drop(columns=['rate_epinephrine', 'rate_norepinephrine','rate_phenylephrine','rate_dopamine'],inplace=True)\n",
    "    \n",
    "\n",
    "    eicu_pos = eicu_df[eicu_df['CAM']==1]\n",
    "    eicu_neg = eicu_df[eicu_df['CAM']==0]\n",
    "\n",
    "    eicu_pos_filtered = pos_selection(eicu_pos,skip_time,min_time)\n",
    "    eicu_neg_filtered = neg_selection(eicu_neg,skip_time,min_time)\n",
    "    eicu_df_filtered = pd.concat([eicu_pos_filtered, eicu_neg_filtered],axis=0)\n",
    "\n",
    "\n",
    "    trg = eicu_df_filtered.groupby('patientunitstayid')\n",
    "\n",
    "    idtr = []\n",
    "    train_np = []\n",
    "    for idx, frame in trg:\n",
    "        idtr.append(idx)\n",
    "        train_np.append(frame)\n",
    "\n",
    "\n",
    "    columns_ord = ['patientunitstayid', 'itemoffset', 'gender','sofa', 'sofa_wo_gcs', 'age', 'admissionheight',\n",
    "           'admissionweight', 'Heart Rate', 'O2 Saturation', 'glucose',\n",
    "           'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'Hemoglobin',\n",
    "           'Platelets', 'Potassium', 'Chloride', 'Bicarbonate', 'Creatinine',\n",
    "            'vent_flag', 'vaso_dose', 'CAM']\n",
    "\n",
    "    def reader_deli(df_list,verbose=1):\n",
    "        X_noncat = []\n",
    "        X_cat = []\n",
    "        deli = []\n",
    "        nrows = []\n",
    "        ts = []\n",
    "        PID = []\n",
    "        nb_unit_stays = len(df_list)\n",
    "        for i, df in enumerate(df_list):\n",
    "            if verbose:\n",
    "                sys.stdout.write('\\rFeed StayID {0} of {1}...'.format(i+1, nb_unit_stays))\n",
    "            dft = df\n",
    "            dummy = pd.DataFrame(columns=columns_ord)\n",
    "            for c in columns_ord:\n",
    "                dummy[c] = dft[c]        \n",
    "            dft = dummy\n",
    "            narr = np.array(dft)\n",
    "            pid = narr[0,0]\n",
    "            x_cat    = narr[:,2:5]\n",
    "            x_noncat = narr[:, 5:-1]\n",
    "            labeldeli = narr[0, -1]\n",
    "            time = narr[:,1]\n",
    "            X_cat.append(x_cat)\n",
    "            X_noncat.append(x_noncat)\n",
    "            deli.append(labeldeli)\n",
    "            ts.append(time)\n",
    "            nrows.append(narr.shape[0])\n",
    "            PID.append(pid)\n",
    "        PID = np.array(PID)    \n",
    "        X_cat = np.array(X_cat)\n",
    "        X_noncat = np.array(X_noncat)\n",
    "        deli = np.array(deli)\n",
    "        ts= np.array(ts)\n",
    "        return PID,X_cat,X_noncat,ts,nrows,deli\n",
    "    \n",
    "    PID_tr,X_cat_tr,X_num_tr,ts_tr,nrows_tr,y_tr = reader_deli(train_np)\n",
    "    \n",
    "    def pad(arr, max_len= min_time):\n",
    "        tmp = np.zeros((max_len, arr.shape[1]))\n",
    "        tmp[:arr.shape[0], :arr.shape[1]] = arr\n",
    "        return tmp  \n",
    "    def ret_numpy(X):\n",
    "        X_list = []\n",
    "        for n in X:\n",
    "            X_list.append(pad(n))\n",
    "        return np.array(X_list)\n",
    "    \n",
    "    X_cat_tr = ret_numpy(X_cat_tr)\n",
    "    X_num_tr = ret_numpy(X_num_tr)\n",
    "\n",
    "    X_train = np.concatenate([X_num_tr,X_cat_tr],axis=-1)\n",
    "    y_train = y_tr\n",
    "\n",
    "    \n",
    "    def data_reader(X,y):\n",
    "        return X,y\n",
    "    \n",
    "    def f1(y_true, y_pred):\n",
    "        y_pred = K.round(y_pred)\n",
    "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "        tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "        p = tp / (tp + fp + K.epsilon())\n",
    "        r = tp / (tp + fn + K.epsilon())\n",
    "        f1 = 2*p*r / (p+r+K.epsilon())\n",
    "        f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "        return K.mean(f1)\n",
    "    \n",
    "    def plot_acc(history):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        return plt.show()\n",
    "    def plot_loss(history):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        return plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_cum_auc(x_y, models, savename='plot.png', x_label='False Positive Rate', y_label='True Positive Rate',auprc=False, thr=0):\n",
    "    \n",
    "        colors = ['b', 'r','g']\n",
    "        for i, (x_y_tuple, m) in enumerate(zip(x_y, models)):\n",
    "            plt.plot(x_y_tuple[0], x_y_tuple[1],label='{}: {:.4f}'.format(m,auc(x_y_tuple[0], x_y_tuple[1])), color=colors[i])\n",
    "        if auprc:\n",
    "            plt.plot([0, 1], [thr, thr], linestyle='--', lw=2, color='k',label=\"Random: {:.4f}\".format(thr), alpha=.8)\n",
    "\n",
    "        else:\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k',label=\"Random: {:.4f}\".format(0.5000), alpha=.8)\n",
    "\n",
    "        plt.xlabel(x_label, fontsize=15)\n",
    "        plt.ylabel(y_label, fontsize=15)\n",
    "        plt.axhline(0, color='black')\n",
    "        plt.axvline(0, color='black')\n",
    "\n",
    "        if auprc:\n",
    "            legend = plt.legend(loc=\"upper left\", prop={'size': 10}, bbox_to_anchor=(0.6, 0.95))\n",
    "        else:\n",
    "            legend = plt.legend(loc=\"lower right\", prop={'size': 10}, bbox_to_anchor=(1, 0.05))\n",
    "            \n",
    "        plt.savefig(savename,\n",
    "                     dpi=400, facecolor='white', transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    ###########################################################\n",
    "    def compute_metrics(X_test,y_test,y_probs):\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "        specat90 = 1-fpr[tpr>=0.90][0]\n",
    "        intrp = interp(np.linspace(0, 1, 100), fpr, tpr)\n",
    "        intrp[0] = 0.0\n",
    "\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        TN,FP,FN,TP = confusion_matrix(y_test, y_probs.round()).ravel()\n",
    "        PPV = TP/(TP+FP)\n",
    "        NPV = TN/(TN+FN)\n",
    "\n",
    "\n",
    "        mcc = matthews_corrcoef(y_test, y_probs.round())\n",
    "        \n",
    "        #####################################################\n",
    "        cw = get_class_weights(X_test,y_test)\n",
    "        indx_pos = np.where(y_test == 1)\n",
    "        indx_neg = np.where(y_test == 0)\n",
    "        sample_w = np.array(np.zeros(len(y_test)))\n",
    "        sample_w[indx_pos[0]] = cw[1]\n",
    "        sample_w[indx_neg[0]] = cw[0]\n",
    "        \n",
    "        #####################################################\n",
    "        \n",
    "        recall_single  = recall_score(y_test,y_probs.round())\n",
    "        \n",
    "        average_precision = average_precision_score(y_test, y_probs)\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "        prs = interp(np.linspace(0, 1, 100), recall[::-1], precision[::-1])\n",
    "        prs[0] = 1.0\n",
    "        prs[-1] = 0.0\n",
    "        auc_prc = auc(recall, precision)\n",
    "        \n",
    "        return {'specat90': specat90, 'intrp': intrp,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr, 'auc': roc_auc,\n",
    "                'ppv': PPV, 'npv': NPV,\n",
    "                'auc_prc': auc_prc,\n",
    "                'prc':precision,\n",
    "                'prs':prs,\n",
    "                'rec':recall,\n",
    "                'mcc': mcc,\n",
    "                'rec_single':recall_single}\n",
    "    \n",
    "    \n",
    "    \n",
    "    def avg_metrics(results):\n",
    "    \n",
    "        mean_fpr = np.linspace(0,1,100)\n",
    "        mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "        mean_tpr = np.mean([results[k]['intrp'] for k in results], axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        std_tpr = np.std([results[k]['intrp'] for k in results], axis=0)\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std([results[k]['auc'] for k in results])\n",
    "        ppvs = np.mean([results[k]['ppv'] for k in results])\n",
    "        npvs = np.mean([results[k]['npv'] for k in results])\n",
    "        mccs = np.mean([results[k]['mcc'] for k in results])\n",
    "        specat90 = np.mean([results[k]['specat90'] for k in results])\n",
    "\n",
    "        mean_precision = np.mean([results[k]['prs'] for k in results], axis=0)\n",
    "        mean_precision[-1] = 0.0\n",
    "        #########################\n",
    "        mean_precision[0] = 1.0\n",
    "        ########################\n",
    "        mean_auc_prc = auc(mean_recall, mean_precision)\n",
    "        std_auc_prc = np.std([results[k]['auc_prc'] for k in results], axis=0)\n",
    "        recall_single = np.mean([results[k]['rec_single'] for k in results])\n",
    "        \n",
    "        ######################CI#########################\n",
    "        l_CI, h_CI = sms.DescrStatsW([results[k]['auc'] for k in results]).tconfint_mean()\n",
    "        auprc_l_CI, auprc_h_CI = sms.DescrStatsW([results[k]['auc_prc'] for k in results]).tconfint_mean()\n",
    "        p_l_CI, p_h_CI = sms.DescrStatsW([results[k]['ppv'] for k in results]).tconfint_mean()\n",
    "        r_l_CI, r_h_CI = sms.DescrStatsW([results[k]['rec_single'] for k in results]).tconfint_mean()\n",
    "        ######################CI#########################\n",
    "        print(\"Mean AUC: {0:0.4f} +- STD{1:0.4f}\".format(mean_auc,std_auc))\n",
    "        print(\"AUPRC: {0:0.4f} +- STD{1:0.4f}\".format(mean_auc_prc,std_auc_prc))\n",
    "        \n",
    "            ######################CI#########################\n",
    "        print(\"L_CI: {0:0.4f}, H_CI: {1:0.4f}\".format(l_CI, h_CI))\n",
    "        print(\"AUPRC_L_CI: {0:0.4f}, AUPRC_H_CI: {1:0.4f}\".format(auprc_l_CI, auprc_h_CI))\n",
    "        print(\"P_L_CI: {0:0.4f}, P_H_CI: {1:0.4f}\".format(p_l_CI, p_h_CI))\n",
    "        print(\"R_L_CI: {0:0.4f}, R_H_CI: {1:0.4f}\".format(r_l_CI, r_h_CI))\n",
    "            ######################CI#########################\n",
    "    \n",
    "        print(\"PPV: {0:0.4f}\".format(ppvs))\n",
    "        print(\"NPV: {0:0.4f}\".format(npvs))\n",
    "        print(\"MCC: {0:0.4f}\".format(mccs))\n",
    "        print(\"Spec@90: {0:0.4f}\".format(specat90))\n",
    "        print(\"Recall: {0:0.4f}\".format(recall_single))\n",
    "        \n",
    "\n",
    "        return {'mean_auc': mean_auc,\n",
    "                'tpr': mean_tpr,\n",
    "                'std_auc':std_auc,\n",
    "                'std_tpr': std_tpr,\n",
    "                'ppv':ppvs,\n",
    "                'npv':npvs,\n",
    "                'mean_auc_prc':mean_auc_prc,\n",
    "                'std_auc_prc':std_auc_prc,\n",
    "                'mean_prc':mean_precision,\n",
    "                'mean_recall':mean_recall,\n",
    "                'mcc':mccs,\n",
    "                'spec@90':specat90,\n",
    "                'rec_single': recall_single,\n",
    "                'l_CI':l_CI,\n",
    "                'h_CI':h_CI,\n",
    "                \n",
    "                'p_l_CI':p_l_CI,\n",
    "                'p_h_CI':p_h_CI,\n",
    "                \n",
    "                'r_l_CI':r_l_CI,\n",
    "                'r_h_CI':r_h_CI,\n",
    "                \n",
    "                'auprc_l_CI':auprc_l_CI,\n",
    "                'auprc_h_CI':auprc_h_CI}\n",
    "\n",
    "    def plot_auc(result):\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='red',\n",
    "                 label='Random', alpha=.8)\n",
    "\n",
    "        mean_fpr = np.linspace(0,1,100)\n",
    "        mean_tpr = result['tpr']\n",
    "        mean_auc = result['mean_auc']\n",
    "        std_auc = result['std_auc']\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "                 label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "        std_tpr = result['std_tpr']\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    if CV:\n",
    "        X_train,y_train= data_reader(X_train,y_train)\n",
    "        \n",
    "    # ORIGINAL\n",
    "    def build_model(X_train,params):\n",
    "        adam = optimizers.Adam(lr=params['lr'],decay=1e-6)\n",
    "\n",
    "        input1 = keras.layers.Input(shape=(X_train.shape[1], 18),name='inp1')\n",
    "\n",
    "        input2 = keras.layers.Input(shape=(X_train.shape[1], 3),name='inp2')\n",
    "\n",
    "        x2 = Embedding(50, 2,name='emb',mask_zero=True)(input2)\n",
    "        x2 = Lambda(lambda x2: x2, output_shape=lambda s:s)(x2)\n",
    "        x2 = Reshape((int(x2.shape[1]),int(x2.shape[2]*x2.shape[3])),name='reshape1')(x2)\n",
    "\n",
    "        merge = keras.layers.Concatenate(axis=-1,name='concat')([input1, x2])\n",
    "        mask  = Masking(mask_value=0.,name=\"maski\")(merge)\n",
    "\n",
    "        lstm1 = Bidirectional(LSTM(units=params['hidden_units'], name= \"lstm1\",\n",
    "                                   kernel_initializer='glorot_normal',return_sequences=False))(mask)\n",
    "        lstm1 = Dropout(params['dropout'])(lstm1)  \n",
    "        out = Dense(1,activation=\"sigmoid\")(lstm1) \n",
    "\n",
    "        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def run_models(X_train, y_train, X_test, model,params=params ,savepath=None):\n",
    "        cw = get_class_weights(X_train, y_train)\n",
    "        if model == \"LSTM\":\n",
    "            clf = build_model(X_train,params)\n",
    "\n",
    "            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "            checkpoint = ModelCheckpoint(filepath=savepath, monitor='val_f1',save_weights_only=False,\n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "            history = clf.fit([X_train[:,:,:18],X_train[:,:,18:]], y_train, batch_size=BATCH_SIZE,#validation_split=0.2,\n",
    "                                class_weight=cw, epochs=params['epochs'],verbose=1,shuffle=True)#,\n",
    "            clf.save(savepath)\n",
    "            clf = load_model(savepath, custom_objects={'f1': f1})\n",
    "\n",
    "            probs = clf.predict([X_test[:,:,:18],X_test[:,:,18:]])\n",
    "\n",
    "        else:\n",
    "            X_train_base = np.reshape(X_train,(X_train.shape[0],-1))\n",
    "            y_train_base =np.expand_dims(y_train,axis=1)            \n",
    "            X_test_base = np.reshape(X_test,(X_test.shape[0],-1))\n",
    "\n",
    "            if model == \"LR\":\n",
    "                clf = LogisticRegression(random_state=0, solver='liblinear',\n",
    "                                     class_weight=cw).fit(X_train_base, y_train_base)\n",
    "            elif model == \"RF\":\n",
    "                clf = RandomForestClassifier(n_estimators=300, max_depth=6,random_state=36, max_features=8,class_weight=cw)\\\n",
    "                .fit(X_train_base, y_train_base)\n",
    "            else:\n",
    "                print('Invalid model name')\n",
    "\n",
    "            probs = clf.predict_proba(X_test_base)[:, 1] \n",
    "\n",
    "        return probs\n",
    "    \n",
    "    def model_cv(X,y,model):\n",
    "        i = 1\n",
    "        cv_scores = {}\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED_VALUE)\n",
    "        for train, test in kfold.split(X, y):\n",
    "            print(f'Fold: {i}')\n",
    "            X_tr = X[train]\n",
    "            X_ts = X[test]\n",
    "            y_tr = y[train]\n",
    "            y_ts = y[test]\n",
    "            savepath = \"eicu_%s_%d_cv.hdf5\"%(TASK,i)\n",
    "            probs = run_models(X_tr, y_tr, X_ts, model,params,savepath)\n",
    "            cv_scores[i] = compute_metrics(X_ts,y_ts, probs)\n",
    "            i += 1        \n",
    "\n",
    "        cum_scores = avg_metrics(cv_scores)\n",
    "        plot_auc(cum_scores)\n",
    "        return cum_scores\n",
    "    \n",
    "    models = ['LR','RF','LSTM']\n",
    "    results = {}\n",
    "    for m in models:\n",
    "        print(f'**********Model: {m}*********')\n",
    "        results[m] = model_cv(X_train, y_train, model=m)\n",
    "\n",
    "                 \n",
    "   \n",
    "        file_name = '{}min_{}skip_model_{}_eicu_CI_pr.json'.format(min_time,skip_time,m)\n",
    "        reported_results = []\n",
    "        for r in ['mean_auc', 'ppv', 'npv', 'mcc', 'spec@90','mean_auc_prc','rec_single','l_CI','h_CI','p_l_CI','p_h_CI','r_l_CI','r_h_CI','auprc_l_CI','auprc_h_CI']:\n",
    "            \n",
    "            reported_results.append(np.round_(results[m][r],decimals=4))\n",
    "            with open(file_name, 'w') as f:\n",
    "                f.write(str(reported_results))\n",
    "        No_pt = X_train.shape[0]\n",
    "        pos =  y_train[y_train ==1].shape[0]\n",
    "        neg =  y_train[y_train ==0].shape[0]\n",
    "        with open(file_name, 'a') as f:\n",
    "            \n",
    "            f.write(str(\"Total no:\"))\n",
    "            f.write(str(No_pt))\n",
    "            f.write(str(\"positive no:\"))\n",
    "            f.write(str(pos))\n",
    "            f.write(str(\"negative no:\"))\n",
    "            f.write(str(neg))\n",
    "            \n",
    "        ###########################\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    fpr_tprs = [(mean_fpr, results[m]['tpr']) for m in models]\n",
    "    plot_cum_auc(fpr_tprs, models, savename='{}_cv_eicu_CI_pr.png'.format(TASK),auprc=False)\n",
    "\n",
    "    thr = sum(y_train)/len(y_train)\n",
    "    \n",
    "    mean_prc_rec = [(np.linspace(0,1,100), results[m]['mean_prc']) for m in models]\n",
    "    plot_cum_auc(mean_prc_rec, models, savename='{}_cv_prc_eicu_CI_pr.png'.format(TASK), x_label='Recall', y_label='Precision',auprc=True,thr=thr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in [48,24,12]:#min time\n",
    "    for s in [96,72,48,24,12]:#pred time\n",
    "        get_eicu_result(m,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eicu_result_recall(min_time,skip_time):\n",
    "\n",
    "    SEED_VALUE = 36\n",
    "    seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    random.seed(SEED_VALUE)\n",
    "    os.environ['PYTHONHASHSEED']=str(SEED_VALUE)\n",
    "    tf.set_random_seed(SEED_VALUE)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "    \n",
    "    CV = True\n",
    "    BATCH_SIZE = 128\n",
    "    TASK = '%d_%d'%(min_time,skip_time)\n",
    "    params = {'lr':0.000075,'hidden_units':128,'dropout':0.2,'epochs':50}\n",
    "    #pos\n",
    "    def pos_selection(df_pos,skip_time,min_time):\n",
    "        posl = []\n",
    "        posdf = pd.DataFrame(columns=df_pos.columns)\n",
    "        all_matches = df_pos[df_pos['labelpt'] == df_pos['labelrec']]\n",
    "\n",
    "        for i, p_id in enumerate(all_matches['patientunitstayid'].unique()):\n",
    "            df_p_id = df_pos[df_pos['patientunitstayid'] == p_id]\n",
    "            idx = all_matches[all_matches['patientunitstayid'] == p_id].index[0]\n",
    "            t = df_pos.iloc[idx].itemoffset\n",
    "            if t > (min_time + skip_time):\n",
    "                posl.append(df_p_id[(df_p_id['itemoffset'] < (t-skip_time)) & (df_p_id['itemoffset'] > (t-(skip_time+min_time)))])\n",
    "\n",
    "        posdf = pd.concat(posl,axis=0)\n",
    "        return posdf\n",
    "\n",
    "    #neg\n",
    "    def neg_selection(df_neg,skip_time,min_time):\n",
    "        negl = []\n",
    "        negdf = pd.DataFrame(columns=df_neg.columns)\n",
    "\n",
    "        for i, p_id in enumerate(df_neg['patientunitstayid'].unique()):\n",
    "            df_p_id = df_neg[df_neg['patientunitstayid'] == p_id]\n",
    "            t = df_p_id.iloc[-1].itemoffset\n",
    "            if t > (min_time + skip_time):\n",
    "                negl.append(df_p_id[(df_p_id['itemoffset'] < (t-skip_time)) &(df_p_id['itemoffset'] > (t-(min_time+skip_time)))])\n",
    "        negdf = pd.concat(negl,axis=0)\n",
    "        return negdf\n",
    "    eicu_df  = pd.read_csv(\"eicu_df_all_24los_normed.csv\")\n",
    "    eicu_pos = eicu_df[eicu_df['CAM']==1]\n",
    "    eicu_neg = eicu_df[eicu_df['CAM']==0]\n",
    "\n",
    "    eicu_pos_filtered = pos_selection(eicu_pos,skip_time,min_time)\n",
    "    eicu_neg_filtered = neg_selection(eicu_neg,skip_time,min_time)\n",
    "    eicu_df_filtered = pd.concat([eicu_pos_filtered, eicu_neg_filtered],axis=0)\n",
    "    trg = eicu_df_filtered.groupby('patientunitstayid')\n",
    "\n",
    "    idtr = []\n",
    "    train_np = []\n",
    "    for idx, frame in trg:\n",
    "        idtr.append(idx)\n",
    "        train_np.append(frame)\n",
    "\n",
    "\n",
    "    columns_ord = ['patientunitstayid', 'itemoffset', 'gender','sofa', 'sofa_wo_gcs', 'age', 'admissionheight',\n",
    "           'admissionweight', 'Heart Rate', 'O2 Saturation', 'glucose',\n",
    "           'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'Hemoglobin',\n",
    "           'Platelets', 'Potassium', 'Chloride', 'Bicarbonate', 'Creatinine',\n",
    "            'vent_flag', 'rate_dopamine', 'rate_epinephrine',\n",
    "           'rate_norepinephrine', 'rate_phenylephrine', 'CAM']\n",
    "\n",
    "    def reader_deli(df_list,verbose=1):\n",
    "        X_noncat = []\n",
    "        X_cat = []\n",
    "        deli = []\n",
    "        nrows = []\n",
    "        ts = []\n",
    "        PID = []\n",
    "        nb_unit_stays = len(df_list)\n",
    "        for i, df in enumerate(df_list):\n",
    "            if verbose:\n",
    "                sys.stdout.write('\\rFeed StayID {0} of {1}...'.format(i+1, nb_unit_stays))\n",
    "            dft = df\n",
    "            dummy = pd.DataFrame(columns=columns_ord)\n",
    "            for c in columns_ord:\n",
    "                dummy[c] = dft[c]        \n",
    "            dft = dummy\n",
    "            narr = np.array(dft)\n",
    "            pid = narr[0,0]\n",
    "            x_cat    = narr[:,2:5]\n",
    "            x_noncat = narr[:, 5:-1]\n",
    "            labeldeli = narr[0, -1]\n",
    "            time = narr[:,1]\n",
    "            X_cat.append(x_cat)\n",
    "            X_noncat.append(x_noncat)\n",
    "            deli.append(labeldeli)\n",
    "            ts.append(time)\n",
    "            nrows.append(narr.shape[0])\n",
    "            PID.append(pid)\n",
    "        PID = np.array(PID)    \n",
    "        X_cat = np.array(X_cat)\n",
    "        X_noncat = np.array(X_noncat)\n",
    "        deli = np.array(deli)\n",
    "        ts= np.array(ts)\n",
    "        return PID,X_cat,X_noncat,ts,nrows,deli\n",
    "    \n",
    "    PID_tr,X_cat_tr,X_num_tr,ts_tr,nrows_tr,y_tr = reader_deli(train_np)\n",
    "    \n",
    "    def pad(arr, max_len= min_time):\n",
    "        tmp = np.zeros((max_len, arr.shape[1]))\n",
    "        tmp[:arr.shape[0], :arr.shape[1]] = arr\n",
    "        return tmp  \n",
    "    def ret_numpy(X):\n",
    "        X_list = []\n",
    "        for n in X:\n",
    "            X_list.append(pad(n))\n",
    "        return np.array(X_list)\n",
    "    \n",
    "    X_cat_tr = ret_numpy(X_cat_tr)\n",
    "    X_num_tr = ret_numpy(X_num_tr)\n",
    "\n",
    "    X_train = np.concatenate([X_num_tr,X_cat_tr],axis=-1)\n",
    "    y_train = y_tr\n",
    "\n",
    "    \n",
    "    def data_reader(X,y):\n",
    "        return X,y\n",
    "    \n",
    "    def f1(y_true, y_pred):\n",
    "        y_pred = K.round(y_pred)\n",
    "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "        tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "        p = tp / (tp + fp + K.epsilon())\n",
    "        r = tp / (tp + fn + K.epsilon())\n",
    "        f1 = 2*p*r / (p+r+K.epsilon())\n",
    "        f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "        return K.mean(f1)\n",
    "    \n",
    "    def plot_acc(history):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        return plt.show()\n",
    "    def plot_loss(history):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        return plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_cum_auc(x_y, models, savename='plot.png', x_label='False Positive Rate', y_label='True Positive Rate',auprc=False, thr=0):\n",
    "    \n",
    "        colors = ['b', 'r','g']\n",
    "        for i, (x_y_tuple, m) in enumerate(zip(x_y, models)):\n",
    "            plt.plot(x_y_tuple[0], x_y_tuple[1],label='{}: {:.4f}'.format(m,auc(x_y_tuple[0], x_y_tuple[1])), color=colors[i])\n",
    "        if auprc:\n",
    "            plt.plot([0, 1], [thr, thr], linestyle='--', lw=2, color='k',label=\"Random: {:.4f}\".format(thr), alpha=.8)\n",
    "\n",
    "        else:\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k',label=\"Random: {:.4f}\".format(0.5000), alpha=.8)\n",
    "\n",
    "        plt.xlabel(x_label, fontsize=15)\n",
    "        plt.ylabel(y_label, fontsize=15)\n",
    "        plt.axhline(0, color='black')\n",
    "        plt.axvline(0, color='black')\n",
    "\n",
    "        if auprc:\n",
    "            legend = plt.legend(loc=\"upper left\", prop={'size': 10}, bbox_to_anchor=(0.6, 0.95))\n",
    "        else:\n",
    "            legend = plt.legend(loc=\"lower right\", prop={'size': 10}, bbox_to_anchor=(1, 0.05))\n",
    "            \n",
    "        plt.savefig(savename,\n",
    "                     dpi=400, facecolor='white', transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    ###############################################\n",
    "    def get_class_weights_recall(data, label):\n",
    "        neg = data[label==0].shape[0]\n",
    "        pos = len(data) - neg\n",
    "        weight_for_0 = (1 / neg)*((pos+neg))/2.0 \n",
    "        weight_for_1 = (1 / pos)*((pos+neg))\n",
    "        return {0:weight_for_0 , 1:(weight_for_1)*2}\n",
    "        \n",
    "    ###########################################################\n",
    "    def compute_metrics(X_test,y_test,y_probs):\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "        specat90 = 1-fpr[tpr>=0.90][0]\n",
    "        intrp = interp(np.linspace(0, 1, 100), fpr, tpr)\n",
    "        intrp[0] = 0.0\n",
    "\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        TN,FP,FN,TP = confusion_matrix(y_test, y_probs.round()).ravel()\n",
    "        PPV = TP/(TP+FP)\n",
    "        NPV = TN/(TN+FN)\n",
    "\n",
    "\n",
    "        mcc = matthews_corrcoef(y_test, y_probs.round())\n",
    "        \n",
    "        #####################################################\n",
    "        cw = get_class_weights_recall(X_test,y_test)\n",
    "#         import pdb;pdb.set_trace()\n",
    "        indx_pos = np.where(y_test == 1)\n",
    "        indx_neg = np.where(y_test == 0)\n",
    "        sample_w = np.array(np.zeros(len(y_test)))\n",
    "        sample_w[indx_pos[0]] = cw[1]\n",
    "        sample_w[indx_neg[0]] = cw[0]\n",
    "        \n",
    "        #####################################################\n",
    "        \n",
    "        recall_single  = recall_score(y_test,y_probs.round())        \n",
    "        average_precision = average_precision_score(y_test, y_probs)\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "        prs = interp(np.linspace(0, 1, 100), recall[::-1], precision[::-1])\n",
    "        prs[0] = 1.0\n",
    "        prs[-1] = 0.0\n",
    "        auc_prc = auc(recall, precision)\n",
    "\n",
    "        return {'specat90': specat90, 'intrp': intrp,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr, 'auc': roc_auc,\n",
    "                'ppv': PPV, 'npv': NPV,\n",
    "                'auc_prc': auc_prc,\n",
    "                'prc':precision,\n",
    "                'prs':prs,\n",
    "                'rec':recall,\n",
    "                'mcc': mcc,\n",
    "                'rec_single':recall_single}\n",
    "\n",
    "\n",
    "    def avg_metrics(results):\n",
    "    \n",
    "        mean_fpr = np.linspace(0,1,100)\n",
    "        mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "        mean_tpr = np.mean([results[k]['intrp'] for k in results], axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        std_tpr = np.std([results[k]['intrp'] for k in results], axis=0)\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std([results[k]['auc'] for k in results])\n",
    "        ppvs = np.mean([results[k]['ppv'] for k in results])\n",
    "        npvs = np.mean([results[k]['npv'] for k in results])\n",
    "        mccs = np.mean([results[k]['mcc'] for k in results])\n",
    "        specat90 = np.mean([results[k]['specat90'] for k in results])\n",
    "\n",
    "        mean_precision = np.mean([results[k]['prs'] for k in results], axis=0)\n",
    "        mean_precision[-1] = 0.0\n",
    "        #########################\n",
    "        mean_precision[0] = 1.0\n",
    "        ########################\n",
    "        mean_auc_prc = auc(mean_recall, mean_precision)\n",
    "        std_auc_prc = np.std([results[k]['auc_prc'] for k in results], axis=0)\n",
    "        \n",
    "        recall_single = np.mean([results[k]['rec_single'] for k in results])\n",
    "        \n",
    "        ######################CI#########################\n",
    "        l_CI, h_CI = sms.DescrStatsW([results[k]['auc'] for k in results]).tconfint_mean()\n",
    "        auprc_l_CI, auprc_h_CI = sms.DescrStatsW([results[k]['auc_prc'] for k in results]).tconfint_mean()\n",
    "        p_l_CI, p_h_CI = sms.DescrStatsW([results[k]['ppv'] for k in results]).tconfint_mean()\n",
    "        r_l_CI, r_h_CI = sms.DescrStatsW([results[k]['rec_single'] for k in results]).tconfint_mean()\n",
    "        ######################CI#########################\n",
    "        print(\"Mean AUC: {0:0.4f} +- STD{1:0.4f}\".format(mean_auc,std_auc))\n",
    "        print(\"AUPRC: {0:0.4f} +- STD{1:0.4f}\".format(mean_auc_prc,std_auc_prc))\n",
    "        \n",
    "            ######################CI#########################\n",
    "        print(\"L_CI: {0:0.4f}, H_CI: {1:0.4f}\".format(l_CI, h_CI))\n",
    "        print(\"AUPRC_L_CI: {0:0.4f}, AUPRC_H_CI: {1:0.4f}\".format(auprc_l_CI, auprc_h_CI))\n",
    "        print(\"P_L_CI: {0:0.4f}, P_H_CI: {1:0.4f}\".format(p_l_CI, p_h_CI))\n",
    "        print(\"R_L_CI: {0:0.4f}, R_H_CI: {1:0.4f}\".format(r_l_CI, r_h_CI))\n",
    "            ######################CI#########################\n",
    "    \n",
    "        print(\"PPV: {0:0.4f}\".format(ppvs))\n",
    "        print(\"NPV: {0:0.4f}\".format(npvs))\n",
    "        print(\"MCC: {0:0.4f}\".format(mccs))\n",
    "        print(\"Spec@90: {0:0.4f}\".format(specat90))\n",
    "        print(\"Recall: {0:0.4f}\".format(recall_single))\n",
    "        \n",
    "\n",
    "        return {'mean_auc': mean_auc,\n",
    "                'tpr': mean_tpr,\n",
    "                'std_auc':std_auc,\n",
    "                'std_tpr': std_tpr,\n",
    "                'ppv':ppvs,\n",
    "                'npv':npvs,\n",
    "                'mean_auc_prc':mean_auc_prc,\n",
    "                'std_auc_prc':std_auc_prc,\n",
    "                'mean_prc':mean_precision,\n",
    "                'mean_recall':mean_recall,\n",
    "                'mcc':mccs,\n",
    "                'spec@90':specat90,\n",
    "                'rec_single': recall_single,\n",
    "                'l_CI':l_CI,\n",
    "                'h_CI':h_CI,\n",
    "                \n",
    "                'p_l_CI':p_l_CI,\n",
    "                'p_h_CI':p_h_CI,\n",
    "                \n",
    "                'r_l_CI':r_l_CI,\n",
    "                'r_h_CI':r_h_CI,\n",
    "                \n",
    "                'auprc_l_CI':auprc_l_CI,\n",
    "                'auprc_h_CI':auprc_h_CI}\n",
    "    \n",
    "    def plot_auc(result):\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='red',\n",
    "                 label='Random', alpha=.8)\n",
    "\n",
    "        mean_fpr = np.linspace(0,1,100)\n",
    "        mean_tpr = result['tpr']\n",
    "        mean_auc = result['mean_auc']\n",
    "        std_auc = result['std_auc']\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "                 label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "        std_tpr = result['std_tpr']\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    if CV:\n",
    "        X_train,y_train= data_reader(X_train,y_train)\n",
    "        \n",
    "    # ORIGINAL\n",
    "    def build_model(X_train,params):\n",
    "        adam = optimizers.Adam(lr=params['lr'],decay=1e-6)\n",
    "\n",
    "        input1 = keras.layers.Input(shape=(X_train.shape[1], 21),name='inp1')\n",
    "\n",
    "        input2 = keras.layers.Input(shape=(X_train.shape[1], 3),name='inp2')\n",
    "\n",
    "        x2 = Embedding(50, 2,name='emb',mask_zero=True)(input2)\n",
    "        x2 = Lambda(lambda x2: x2, output_shape=lambda s:s)(x2)\n",
    "        x2 = Reshape((int(x2.shape[1]),int(x2.shape[2]*x2.shape[3])),name='reshape1')(x2)\n",
    "\n",
    "        merge = keras.layers.Concatenate(axis=-1,name='concat')([input1, x2])\n",
    "        mask  = Masking(mask_value=0.,name=\"maski\")(merge)\n",
    "\n",
    "        lstm1 = Bidirectional(LSTM(units=params['hidden_units'], name= \"lstm1\",\n",
    "                                   kernel_initializer='glorot_normal',return_sequences=False))(mask)\n",
    "        lstm1 = Dropout(params['dropout'])(lstm1)  \n",
    "        out = Dense(1,activation=\"sigmoid\")(lstm1) \n",
    "\n",
    "        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def run_models(X_train, y_train, X_test, model,params=params ,savepath=None):\n",
    "        cw = get_class_weights_recall(X_train, y_train)\n",
    "        if model == \"LSTM\":\n",
    "            clf = build_model(X_train,params)\n",
    "\n",
    "            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "            checkpoint = ModelCheckpoint(filepath=savepath, monitor='val_f1',save_weights_only=False,\n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "            history = clf.fit([X_train[:,:,:21],X_train[:,:,21:]], y_train, batch_size=BATCH_SIZE,#validation_split=0.2,\n",
    "                                class_weight=cw, epochs=params['epochs'],verbose=1,shuffle=True)#,\n",
    "            clf.save(savepath)\n",
    "            clf = load_model(savepath, custom_objects={'f1': f1})\n",
    "\n",
    "            probs = clf.predict([X_test[:,:,:21],X_test[:,:,21:]])\n",
    "\n",
    "        else:\n",
    "            X_train_base = np.reshape(X_train,(X_train.shape[0],-1))\n",
    "            y_train_base =np.expand_dims(y_train,axis=1)            \n",
    "            X_test_base = np.reshape(X_test,(X_test.shape[0],-1))\n",
    "\n",
    "            if model == \"LR\":\n",
    "                clf = LogisticRegression(random_state=0, solver='liblinear',\n",
    "                                     class_weight=cw).fit(X_train_base, y_train_base)\n",
    "            elif model == \"RF\":\n",
    "                clf = RandomForestClassifier(n_estimators=300, max_depth=6,random_state=36, max_features=8,class_weight=cw)\\\n",
    "                .fit(X_train_base, y_train_base)\n",
    "            else:\n",
    "                print('Invalid model name')\n",
    "\n",
    "            probs = clf.predict_proba(X_test_base)[:, 1] \n",
    "\n",
    "        return probs\n",
    "    \n",
    "    def model_cv(X,y,model):\n",
    "        i = 1\n",
    "        cv_scores = {}\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED_VALUE)\n",
    "        for train, test in kfold.split(X, y):\n",
    "            print(f'Fold: {i}')\n",
    "            X_tr = X[train]\n",
    "            X_ts = X[test]\n",
    "            y_tr = y[train]\n",
    "            y_ts = y[test]\n",
    "            savepath = \"eicu_%s_%d_recall_cv_CI.hdf5\"%(TASK,i)\n",
    "            probs = run_models(X_tr, y_tr, X_ts, model,params,savepath)\n",
    "            cv_scores[i] = compute_metrics(X_ts,y_ts, probs)\n",
    "            i += 1        \n",
    "\n",
    "        cum_scores = avg_metrics(cv_scores)\n",
    "        plot_auc(cum_scores)\n",
    "        return cum_scores\n",
    "    \n",
    "    models = ['LR','RF','LSTM']\n",
    "    results = {}\n",
    "    for m in models:\n",
    "        print(f'**********Model: {m}*********')\n",
    "        results[m] = model_cv(X_train, y_train, model=m)\n",
    "\n",
    "                 \n",
    "   \n",
    "        file_name = '{}min_{}skip_model_{}_eicu_recall_CI_pr.json'.format(min_time,skip_time,m)\n",
    "        reported_results = []\n",
    "        \n",
    "#         for r in ['mean_auc', 'ppv', 'npv', 'mcc', 'spec@90','mean_auc_prc','rec_single','l_CI','h_CI']:\n",
    "        for r in ['mean_auc', 'ppv', 'npv', 'mcc', 'spec@90','mean_auc_prc','rec_single','l_CI','h_CI','p_l_CI','p_h_CI','r_l_CI','r_h_CI','auprc_l_CI','auprc_h_CI']:\n",
    "\n",
    "            \n",
    "            reported_results.append(np.round_(results[m][r],decimals=4))\n",
    "            with open(file_name, 'w') as f:\n",
    "                f.write(str(reported_results))\n",
    "        No_pt = X_train.shape[0]\n",
    "        pos =  y_train[y_train ==1].shape[0]\n",
    "        neg =  y_train[y_train ==0].shape[0]\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(str(\"Total no:\"))\n",
    "            f.write(str(No_pt))\n",
    "            f.write(str(\"positive no:\"))\n",
    "            f.write(str(pos))\n",
    "            f.write(str(\"negative no:\"))\n",
    "            f.write(str(neg))\n",
    "        \n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    fpr_tprs = [(mean_fpr, results[m]['tpr']) for m in models]\n",
    "    plot_cum_auc(fpr_tprs, models, savename='{}_cv_recall_eicu_CI_pr.png'.format(TASK),auprc=False)\n",
    "\n",
    "    thr = sum(y_train)/len(y_train)\n",
    "    \n",
    "    mean_prc_rec = [(np.linspace(0,1,100), results[m]['mean_prc']) for m in models]\n",
    "    plot_cum_auc(mean_prc_rec, models, savename='{}_cv_prc_recall_eicu_CI_pr.png'.format(TASK), x_label='Recall', y_label='Precision',auprc=True,thr=thr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [48,24,12]:#min time\n",
    "    for s in [96,72,48,24,12]: #pred time\n",
    "        get_eicu_result_recall(m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in [24]:#min time\n",
    "    for s in [96,72,48,24,12]: #pred time\n",
    "        get_eicu_result_recall(m,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mimic_result(min_time,skip_time,high_recall= False):\n",
    "\n",
    "    SEED_VALUE = 36\n",
    "    seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    random.seed(SEED_VALUE)\n",
    "    os.environ['PYTHONHASHSEED']=str(SEED_VALUE)\n",
    "    tf.set_random_seed(SEED_VALUE)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)\n",
    "    \n",
    "    CV = True\n",
    "    BATCH_SIZE = 128\n",
    "    TASK = '%d_%d'%(min_time,skip_time)\n",
    "    params = {'lr':0.000075,'hidden_units':128,'dropout':0.2,'epochs':50}\n",
    "    #pos\n",
    "    def pos_selection(df_pos,skip_time,min_time):\n",
    "        posl = []\n",
    "        posdf = pd.DataFrame(columns=df_pos.columns)\n",
    "        all_matches = df_pos[df_pos['labelpt'] == df_pos['labelrec']]\n",
    "\n",
    "        for i, p_id in enumerate(all_matches['patientunitstayid'].unique()):\n",
    "            df_p_id = df_pos[df_pos['patientunitstayid'] == p_id]\n",
    "            idx = all_matches[all_matches['patientunitstayid'] == p_id].index[0]\n",
    "            t = df_pos.iloc[idx].itemoffset\n",
    "            if t > (min_time + skip_time):\n",
    "                posl.append(df_p_id[(df_p_id['itemoffset'] < (t-skip_time)) & (df_p_id['itemoffset'] > (t-(skip_time+min_time)))])\n",
    "\n",
    "        posdf = pd.concat(posl,axis=0)\n",
    "        return posdf\n",
    "\n",
    "    #neg\n",
    "    def neg_selection(df_neg,skip_time,min_time):\n",
    "        negl = []\n",
    "        negdf = pd.DataFrame(columns=df_neg.columns)\n",
    "\n",
    "        for i, p_id in enumerate(df_neg['patientunitstayid'].unique()):\n",
    "            df_p_id = df_neg[df_neg['patientunitstayid'] == p_id]\n",
    "            t = df_p_id.iloc[-1].itemoffset\n",
    "            if t > (min_time + skip_time):\n",
    "                negl.append(df_p_id[(df_p_id['itemoffset'] < (t-skip_time)) &(df_p_id['itemoffset'] > (t-(min_time+skip_time)))])\n",
    "        negdf = pd.concat(negl,axis=0)\n",
    "        return negdf\n",
    "    mimic_df = pd.read_csv(\"mimic_df_all_24los_normed.csv\")\n",
    "\n",
    " # ADD VASO\n",
    "    mimic_df['vaso_dose'] = np.nan\n",
    "    mimic_df['vaso_dose'] = mimic_df['rate_epinephrine']+mimic_df['rate_norepinephrine'] + mimic_df['rate_phenylephrine']/10 + mimic_df['rate_dopamine']/2\n",
    "    mimic_df.drop(columns=['rate_epinephrine', 'rate_norepinephrine','rate_phenylephrine','rate_dopamine'],inplace=True)\n",
    "    mimic_pos = mimic_df[mimic_df['CAM']==1]\n",
    "    mimic_neg = mimic_df[mimic_df['CAM']==0]\n",
    "    mimic_pos_filtered = pos_selection(mimic_pos,skip_time,min_time)\n",
    "    mimic_neg_filtered = neg_selection(mimic_neg,skip_time,min_time)\n",
    "    mimic_df_filtered = pd.concat([mimic_pos_filtered, mimic_neg_filtered],axis=0)\n",
    "\n",
    "    tsg  = mimic_df_filtered.groupby('patientunitstayid')\n",
    "\n",
    "    idts = []\n",
    "    test_np = []\n",
    "    for idx, frame in tsg:\n",
    "        idts.append(idx)\n",
    "        test_np.append(frame)\n",
    "\n",
    "    columns_ord = ['patientunitstayid', 'itemoffset', 'gender','sofa', 'sofa_wo_gcs', 'age', 'admissionheight',\n",
    "           'admissionweight', 'Heart Rate', 'O2 Saturation', 'glucose',\n",
    "           'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'Hemoglobin',\n",
    "           'Platelets', 'Potassium', 'Chloride', 'Bicarbonate', 'Creatinine',\n",
    "            'vent_flag', 'vaso_dose', 'CAM']\n",
    "\n",
    "    def reader_deli(df_list,verbose=1):\n",
    "        X_noncat = []\n",
    "        X_cat = []\n",
    "        deli = []\n",
    "        nrows = []\n",
    "        ts = []\n",
    "        PID = []\n",
    "        nb_unit_stays = len(df_list)\n",
    "        for i, df in enumerate(df_list):\n",
    "            if verbose:\n",
    "                sys.stdout.write('\\rFeed StayID {0} of {1}...'.format(i+1, nb_unit_stays))\n",
    "            dft = df\n",
    "            dummy = pd.DataFrame(columns=columns_ord)\n",
    "            for c in columns_ord:\n",
    "                dummy[c] = dft[c]        \n",
    "            dft = dummy\n",
    "            narr = np.array(dft)\n",
    "            pid = narr[0,0]\n",
    "            x_cat    = narr[:,2:5]\n",
    "            x_noncat = narr[:, 5:-1]\n",
    "            labeldeli = narr[0, -1]\n",
    "            time = narr[:,1]\n",
    "            X_cat.append(x_cat)\n",
    "            X_noncat.append(x_noncat)\n",
    "            deli.append(labeldeli)\n",
    "            ts.append(time)\n",
    "            nrows.append(narr.shape[0])\n",
    "            PID.append(pid)\n",
    "        PID = np.array(PID)    \n",
    "        X_cat = np.array(X_cat)\n",
    "        X_noncat = np.array(X_noncat)\n",
    "        deli = np.array(deli)\n",
    "        ts= np.array(ts)\n",
    "        return PID,X_cat,X_noncat,ts,nrows,deli\n",
    "    \n",
    "    PID_ts,X_cat_ts,X_num_ts,ts_ts,nrows_ts,y_ts = reader_deli(test_np)\n",
    "    \n",
    "    def pad(arr, max_len= min_time):\n",
    "        tmp = np.zeros((max_len, arr.shape[1]))\n",
    "        tmp[:arr.shape[0], :arr.shape[1]] = arr\n",
    "        return tmp  \n",
    "    def ret_numpy(X):\n",
    "        X_list = []\n",
    "        for n in X:\n",
    "            X_list.append(pad(n))\n",
    "        return np.array(X_list)\n",
    "    X_cat_ts = ret_numpy(X_cat_ts)\n",
    "    X_num_ts = ret_numpy(X_num_ts)\n",
    "    X_test  = np.concatenate([X_num_ts,X_cat_ts],axis=-1)\n",
    "    y_test  = y_ts\n",
    "\n",
    "    \n",
    "    def data_reader(X,y):\n",
    "        return X,y\n",
    "    \n",
    "    def f1(y_true, y_pred):\n",
    "        y_pred = K.round(y_pred)\n",
    "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "        tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "        p = tp / (tp + fp + K.epsilon())\n",
    "        r = tp / (tp + fn + K.epsilon())\n",
    "        f1 = 2*p*r / (p+r+K.epsilon())\n",
    "        f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "        return K.mean(f1)\n",
    "    \n",
    "    def plot_acc(history):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        return plt.show()\n",
    "    def plot_loss(history):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        return plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_cum_auc(x_y, models, savename='plot.png', x_label='False Positive Rate', y_label='True Positive Rate',auprc=False, thr=0):\n",
    "    \n",
    "        colors = ['b', 'r','g']\n",
    "        for i, (x_y_tuple, m) in enumerate(zip(x_y, models)):\n",
    "            plt.plot(x_y_tuple[0], x_y_tuple[1],label='{}: {:.4f}'.format(m,auc(x_y_tuple[0], x_y_tuple[1])), color=colors[i])\n",
    "        if auprc:\n",
    "            plt.plot([0, 1], [thr, thr], linestyle='--', lw=2, color='k',label=\"Random: {:.4f}\".format(thr), alpha=.8)\n",
    "\n",
    "        else:\n",
    "            plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k',label=\"Random: {:.4f}\".format(0.5000), alpha=.8)\n",
    "\n",
    "        plt.xlabel(x_label, fontsize=15)\n",
    "        plt.ylabel(y_label, fontsize=15)\n",
    "        plt.axhline(0, color='black')\n",
    "        plt.axvline(0, color='black')\n",
    "\n",
    "        if auprc:\n",
    "            legend = plt.legend(loc=\"upper left\", prop={'size': 10}, bbox_to_anchor=(0.6, 0.95))\n",
    "        else:\n",
    "            legend = plt.legend(loc=\"lower right\", prop={'size': 10}, bbox_to_anchor=(1, 0.05))\n",
    "            \n",
    "        plt.savefig(savename,\n",
    "                     dpi=400, facecolor='white', transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    ###########################################################\n",
    "    def compute_metrics(X_test,y_test,y_probs):\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "        specat90 = 1-fpr[tpr>=0.90][0]\n",
    "        intrp = interp(np.linspace(0, 1, 100), fpr, tpr)\n",
    "        intrp[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        TN,FP,FN,TP = confusion_matrix(y_test, y_probs.round()).ravel()\n",
    "        PPV = TP/(TP+FP)\n",
    "        NPV = TN/(TN+FN)\n",
    "        mcc = matthews_corrcoef(y_test, y_probs.round())\n",
    "        #####################################################\n",
    "        cw = get_class_weights(X_test,y_test)\n",
    "        indx_pos = np.where(y_test == 1)\n",
    "        indx_neg = np.where(y_test == 0)\n",
    "        sample_w = np.array(np.zeros(len(y_test)))\n",
    "        sample_w[indx_pos[0]] = cw[1]\n",
    "        sample_w[indx_neg[0]] = cw[0]\n",
    "        #####################################################\n",
    "        \n",
    "        recall_single  = recall_score(y_test,y_probs.round())\n",
    "        \n",
    "        average_precision = average_precision_score(y_test, y_probs)\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "        prs = interp(np.linspace(0, 1, 100), recall[::-1], precision[::-1])\n",
    "        prs[0] = 1.0\n",
    "        prs[-1] = 0.0\n",
    "\n",
    "        auc_prc = auc(recall, precision)\n",
    "\n",
    "        return {'specat90': specat90, 'intrp': intrp,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr, 'auc': roc_auc,\n",
    "                'ppv': PPV, 'npv': NPV,\n",
    "                'auc_prc': auc_prc,\n",
    "                'prc':precision,\n",
    "                'prs':prs,\n",
    "                'rec':recall,\n",
    "                'mcc': mcc,\n",
    "                'rec_single':recall_single}\n",
    "\n",
    "\n",
    "    def avg_metrics(results):\n",
    "    \n",
    "        mean_fpr = np.linspace(0,1,100)\n",
    "        mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "        mean_tpr = np.mean([results[k]['intrp'] for k in results], axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        std_tpr = np.std([results[k]['intrp'] for k in results], axis=0)\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std([results[k]['auc'] for k in results])\n",
    "        ppvs = np.mean([results[k]['ppv'] for k in results])\n",
    "        npvs = np.mean([results[k]['npv'] for k in results])\n",
    "        mccs = np.mean([results[k]['mcc'] for k in results])\n",
    "        specat90 = np.mean([results[k]['specat90'] for k in results])\n",
    "\n",
    "        mean_precision = np.mean([results[k]['prs'] for k in results], axis=0)\n",
    "        mean_precision[-1] = 0.0\n",
    "        #########################\n",
    "        mean_precision[0] = 1.0\n",
    "        ########################\n",
    "        mean_auc_prc = auc(mean_recall, mean_precision)\n",
    "        std_auc_prc = np.std([results[k]['auc_prc'] for k in results], axis=0)\n",
    "        \n",
    "        recall_single = np.mean([results[k]['rec_single'] for k in results])\n",
    "        \n",
    "        \n",
    "        ######################CI#########################\n",
    "        l_CI, h_CI = sms.DescrStatsW([results[k]['auc'] for k in results]).tconfint_mean()\n",
    "        auprc_l_CI, auprc_h_CI = sms.DescrStatsW([results[k]['auc_prc'] for k in results]).tconfint_mean()\n",
    "        p_l_CI, p_h_CI = sms.DescrStatsW([results[k]['ppv'] for k in results]).tconfint_mean()\n",
    "        r_l_CI, r_h_CI = sms.DescrStatsW([results[k]['rec_single'] for k in results]).tconfint_mean()\n",
    "        ######################CI#########################\n",
    "        print(\"Mean AUC: {0:0.4f} +- STD{1:0.4f}\".format(mean_auc,std_auc))\n",
    "        print(\"AUPRC: {0:0.4f} +- STD{1:0.4f}\".format(mean_auc_prc,std_auc_prc))\n",
    "        \n",
    "        ######################CI#########################\n",
    "        print(\"L_CI: {0:0.4f}, H_CI: {1:0.4f}\".format(l_CI, h_CI))\n",
    "        print(\"AUPRC_L_CI: {0:0.4f}, AUPRC_H_CI: {1:0.4f}\".format(auprc_l_CI, auprc_h_CI))\n",
    "        print(\"P_L_CI: {0:0.4f}, P_H_CI: {1:0.4f}\".format(p_l_CI, p_h_CI))\n",
    "        print(\"R_L_CI: {0:0.4f}, R_H_CI: {1:0.4f}\".format(r_l_CI, r_h_CI))\n",
    "        ######################CI#########################\n",
    "    \n",
    "        print(\"PPV: {0:0.4f}\".format(ppvs))\n",
    "        print(\"NPV: {0:0.4f}\".format(npvs))\n",
    "        print(\"MCC: {0:0.4f}\".format(mccs))\n",
    "        print(\"Spec@90: {0:0.4f}\".format(specat90))\n",
    "        print(\"Recall: {0:0.4f}\".format(recall_single))\n",
    "        \n",
    "\n",
    "        return {'mean_auc': mean_auc,\n",
    "                'tpr': mean_tpr,\n",
    "                'std_auc':std_auc,\n",
    "                'std_tpr': std_tpr,\n",
    "                'ppv':ppvs,\n",
    "                'npv':npvs,\n",
    "                'mean_auc_prc':mean_auc_prc,\n",
    "                'std_auc_prc':std_auc_prc,\n",
    "                'mean_prc':mean_precision,\n",
    "                'mean_recall':mean_recall,\n",
    "                'mcc':mccs,\n",
    "                'spec@90':specat90,\n",
    "                'rec_single': recall_single,\n",
    "                'l_CI':l_CI,\n",
    "                'h_CI':h_CI,\n",
    "                \n",
    "                'p_l_CI':p_l_CI,\n",
    "                'p_h_CI':p_h_CI,\n",
    "                \n",
    "                'r_l_CI':r_l_CI,\n",
    "                'r_h_CI':r_h_CI,\n",
    "                \n",
    "                'auprc_l_CI':auprc_l_CI,\n",
    "                'auprc_h_CI':auprc_h_CI}\n",
    "\n",
    "    def plot_auc(result):\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='red',\n",
    "                 label='Random', alpha=.8)\n",
    "\n",
    "        mean_fpr = np.linspace(0,1,100)\n",
    "        mean_tpr = result['tpr']\n",
    "        mean_auc = result['mean_auc']\n",
    "        std_auc = result['std_auc']\n",
    "        plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "                 label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.4f)' % (mean_auc, std_auc),\n",
    "                 lw=2, alpha=.8)\n",
    "\n",
    "        std_tpr = result['std_tpr']\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                         label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "    def get_class_weights(data, label):\n",
    "        neg = data[label==0].shape[0]\n",
    "        pos = len(data) - neg\n",
    "        weight_for_0 = (1 / neg)*((pos+neg))/2.0 \n",
    "        weight_for_1 = (1 / pos)*((pos+neg))\n",
    "        if high_recall==False:\n",
    "            return {0:weight_for_0 , 1:(weight_for_1)/2}\n",
    "        elif high_recall:\n",
    "            return {0:weight_for_0 , 1:(weight_for_1)}\n",
    "        \n",
    "\n",
    "    if CV:\n",
    "        X_test,y_test= data_reader(X_test,y_test)\n",
    "        \n",
    "    # ORIGINAL\n",
    "    def build_model(X_test,params):\n",
    "        adam = optimizers.Adam(lr=params['lr'],decay=1e-6)\n",
    "\n",
    "        input1 = keras.layers.Input(shape=(X_test.shape[1], 18),name='inp1')\n",
    "\n",
    "        input2 = keras.layers.Input(shape=(X_test.shape[1], 3),name='inp2')\n",
    "\n",
    "        x2 = Embedding(50, 2,name='emb',mask_zero=True)(input2)\n",
    "        x2 = Lambda(lambda x2: x2, output_shape=lambda s:s)(x2)\n",
    "        x2 = Reshape((int(x2.shape[1]),int(x2.shape[2]*x2.shape[3])),name='reshape1')(x2)\n",
    "\n",
    "        merge = keras.layers.Concatenate(axis=-1,name='concat')([input1, x2])\n",
    "        mask  = Masking(mask_value=0.,name=\"maski\")(merge)\n",
    "\n",
    "        lstm1 = Bidirectional(LSTM(units=params['hidden_units'], name= \"lstm1\",\n",
    "                                   kernel_initializer='glorot_normal',return_sequences=False))(mask)\n",
    "        lstm1 = Dropout(params['dropout'])(lstm1)  \n",
    "        out = Dense(1,activation=\"sigmoid\")(lstm1) \n",
    "\n",
    "        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def run_models(X_train, y_train, X_test, model,params=params ,savepath=None):\n",
    "        cw = get_class_weights(X_train, y_train)\n",
    "        if model == \"LSTM\":\n",
    "            clf = build_model(X_train,params)\n",
    "\n",
    "            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "            checkpoint = ModelCheckpoint(filepath=savepath, monitor='val_f1',save_weights_only=False,\n",
    "                                 verbose=1, save_best_only=True, mode='max')\n",
    "            history = clf.fit([X_train[:,:,:18],X_train[:,:,18:]], y_train, batch_size=BATCH_SIZE,#validation_split=0.2,\n",
    "                                class_weight=cw, epochs=params['epochs'],verbose=1,shuffle=True)#,\n",
    "            clf.save(savepath)\n",
    "            clf = load_model(savepath, custom_objects={'f1': f1})\n",
    "\n",
    "            probs = clf.predict([X_test[:,:,:18],X_test[:,:,18:]])\n",
    "\n",
    "        else:\n",
    "            X_train_base = np.reshape(X_train,(X_train.shape[0],-1))\n",
    "            y_train_base =np.expand_dims(y_train,axis=1)            \n",
    "            X_test_base = np.reshape(X_test,(X_test.shape[0],-1))\n",
    "\n",
    "            if model == \"LR\":\n",
    "                clf = LogisticRegression(random_state=0, solver='liblinear',\n",
    "                                     class_weight=cw).fit(X_train_base, y_train_base)\n",
    "            elif model == \"RF\":\n",
    "                clf = RandomForestClassifier(n_estimators=300, max_depth=6,random_state=36, max_features=8,class_weight=cw)\\\n",
    "                .fit(X_train_base, y_train_base)\n",
    "            else:\n",
    "                print('Invalid model name')\n",
    "\n",
    "            probs = clf.predict_proba(X_test_base)[:, 1] \n",
    "\n",
    "        return probs\n",
    "    \n",
    "    def model_cv(X,y,model):\n",
    "        i = 1\n",
    "        cv_scores = {}\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED_VALUE)\n",
    "        for train, test in kfold.split(X, y):\n",
    "            print(f'Fold: {i}')\n",
    "            X_tr = X[train]\n",
    "            X_ts = X[test]\n",
    "            y_tr = y[train]\n",
    "            y_ts = y[test]\n",
    "            if high_recall:\n",
    "                savepath = \"mimic_%s_%d_cv_recall.hdf5\"%(TASK,i)\n",
    "            else:\n",
    "                savepath = \"mimic_%s_%d_cv.hdf5\"%(TASK,i)\n",
    "            probs = run_models(X_tr, y_tr, X_ts, model,params,savepath)\n",
    "            cv_scores[i] = compute_metrics(X_ts,y_ts, probs)\n",
    "            i += 1        \n",
    "\n",
    "        cum_scores = avg_metrics(cv_scores)\n",
    "        plot_auc(cum_scores)\n",
    "        return cum_scores\n",
    "    \n",
    "    models = ['LR','RF','LSTM']\n",
    "    results = {}\n",
    "    for m in models:\n",
    "        print(f'**********Model: {m}*********')\n",
    "        results[m] = model_cv(X_test, y_test, model=m)\n",
    "\n",
    "            \n",
    "        if high_recall:\n",
    "            file_name = '{}min_{}skip_model_{}_mimic_recall_CI_pr.json'.format(min_time,skip_time,m)\n",
    "        else:\n",
    "            file_name = '{}min_{}skip_model_{}_mimic_CI_pr.json'.format(min_time,skip_time,m)\n",
    "        reported_results = []\n",
    "        \n",
    "        for r in ['mean_auc', 'ppv', 'npv', 'mcc', 'spec@90','mean_auc_prc','rec_single','l_CI','h_CI','p_l_CI','p_h_CI','r_l_CI','r_h_CI','auprc_l_CI','auprc_h_CI']:\n",
    "\n",
    "            reported_results.append(np.round_(results[m][r],decimals=4))\n",
    "            with open(file_name, 'w') as f:\n",
    "                f.write(str(reported_results))\n",
    "                \n",
    "        No_pt = X_test.shape[0]\n",
    "        pos =  y_test[y_test ==1].shape[0]\n",
    "        neg =  y_test[y_test ==0].shape[0]\n",
    "        with open(file_name, 'a') as f:\n",
    "            \n",
    "            f.write(str(\"Total no:\"))\n",
    "            f.write(str(No_pt))\n",
    "            f.write(str(\"positive no:\"))\n",
    "            f.write(str(pos))\n",
    "            f.write(str(\"negative no:\"))\n",
    "            f.write(str(neg))\n",
    "            \n",
    "        ###########################\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    fpr_tprs = [(mean_fpr, results[m]['tpr']) for m in models]\n",
    "    if high_recall:\n",
    "        plot_cum_auc(fpr_tprs, models, savename='{}_cv_mimic_recall_CI_pr.png'.format(TASK),auprc=False)\n",
    "    else:\n",
    "        plot_cum_auc(fpr_tprs, models, savename='{}_cv_mimic_CI_pr.png'.format(TASK),auprc=False)\n",
    "        \n",
    "    thr = sum(y_test)/len(y_test)\n",
    "    \n",
    "    mean_prc_rec = [(np.linspace(0,1,100), results[m]['mean_prc']) for m in models]\n",
    "    if high_recall:\n",
    "        plot_cum_auc(mean_prc_rec, models, savename='{}_cv_prc_mimic_recall_CI_pr.png'.format(TASK), x_label='Recall', y_label='Precision',auprc=True,thr=thr)\n",
    "    else:\n",
    "        plot_cum_auc(mean_prc_rec, models, savename='{}_cv_prc_mimic_CI_pr.png'.format(TASK), x_label='Recall', y_label='Precision',auprc=True,thr=thr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher recall\n",
    "for m in [48,24,12]:#min time\n",
    "    for s in [96,72,48,24,12]: #pred time\n",
    "        get_mimic_result(m,s,high_recall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in [12]:#min time\n",
    "    for s in [96,72,48,24,12]: #pred time\n",
    "        get_mimic_result(m,s,high_recall=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deli_env)",
   "language": "python",
   "name": "pdf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
